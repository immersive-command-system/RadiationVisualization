The various folders represents different "modules" (only in an organizational sense, not really in any code sense).
Each folder receives, processes and visualizes one channel or topic of data coming from the drone in real time.
A future improvement would be to combine the features we want into one ROSBridge connection.
- **Occupancy:** this module was the pipeline for processing 3d pointcloud data from **google cartographer**
 (the SLAM solution that tried to figure out where the drone was and make a 3d map of the environment given the drone's lidar and IMU data). 
The official way to get this 3d submap is to export it from cartographer after it has finished running, but while cartographer is running (eg. while the drone is still flying) cartographer does keep an unfinalized working 3d map internally.
We modified someone else's code which would expose this internal 3d mapping to rosbridge as a service and the occupancy model calls that service to get it's data. The modified version of cartographer_ros is here: https://github.com/immersive-command-system/cartographer_ros. 
It should work with the original version of cartographer but both cartographer and cartographer_ros may have been updated since then so if you want to get those updates, you'll have to re-integrate these changes.
- **Radiation:** receives the radiation data messages from the drone. It uses RNDataMsg because that's the real-time data format LBL's system sends it in. I think it is only a proper point cloud after it has been processed offline.
**FUTURE WORK**: Are we going to continue using RNDataMsg or what?
- **Scanning:** this just shows the unprocessed raw lidar data. This is different than occupancy, which is the 3d point cloud representing the estimated 3d map of the environment the drone has seen so far. This just shows the current lidar scan (unfiltered, no error correction, doesn't include anything the lidar can't see currently unlike the 3d map from cartographer which is cumulative). It's not really that useful (unless you guys find it so) it was more of a stepping stone. The raw lidar data was available as one of the topics in the ROSBag we played back to simulate the data coming in from the drone so I thought why not give it a try and figure out how to work with point cloud data.
- **Submap:** this module is even less useful. At the time, we were essentially trying to do what the occupancy module does but without having to modify cartographer itself. Cartographer ros has service where you can request a submap, so we thought, oh great just what we're looking for. Turns out it's a 2d map, and so we pretty much ditched the effort. It sorta works, I think? It just shows up as a mini-map in the corner (like in games)
- **Video:** it wouldn't be an immersive command system if you couldn't see the video feed from the drone. tbh it was also one of those things where we were going down the list of topics recorded in the ROSBag and thought this was a good one to try and parse. Right now this module receives the video data from the topic and plays it in one of the corners of the interface. The biggest issue at the time was that the drone's camera feed comes in as raw, uncompressed video (every pixel is separate), which is infeasible to stream in real time with any reasonable amount of quality. One of the things we planned to do but never got around to was having something on the onboard computer read the video feed, encode/compress it, and then broadcast it on another topic that the remote unity rosbridge can then subscribe to.
